# 为 AI 智能体编写高效的工具——使用 AI 智能体

**发布日期**：2025 年 9 月 11 日

## 概述

智能体的效能取决于我们提供给它们的工具质量。本文介绍了提升各种智能体系统性能的最有效技术。

## 什么是工具？

在计算中，确定性系统在相同输入下总是产生相同输出，而"非确定性"系统（如智能体）即使在相同条件下也能生成不同的响应。

传统软件建立的是确定性系统之间的契约。例如，函数调用 `getWeather("NYC")` 每次调用都会以完全相同的方式获取纽约天气。

工具则反映了确定性系统与非确定性智能体之间的新型契约。当用户询问"我今天应该带伞吗？"时，智能体可能会调用天气工具、使用已有知识回答，甚至先问一个澄清性问题。有时智能体可能会产生幻觉或无法理解如何使用工具。

这意味着在为智能体编写软件时需要从根本上改变思路。我们不应该像为其他开发者或系统编写函数和 API 一样编写工具，而是需要为智能体专门设计工具。

## 编写工具的方法

### 构建原型

首先构建工具的快速原型。使用 Claude Code 编写工具时，为软件库、API 或 SDK（包括 MCP SDK）提供文档会有帮助。LLM 友好的文档通常可在官方文档网站的 `llms.txt` 文件中找到。

将工具包装在本地 MCP 服务器或桌面扩展中，可在 Claude Code 或 Claude 桌面应用中连接和测试工具。

连接本地 MCP 服务器到 Claude Code，运行：
```
claude mcp add <name> <command> [args...]
```

在 Claude 桌面应用中，导航到"设置 > 开发者"或"设置 > 扩展"。

工具也可直接传入 Anthropic API 调用进行程序化测试。

### 运行评估

需要通过运行评估来衡量 Claude 对工具的使用效果。从生成大量评估任务开始，这些任务应基于真实用例。建议与智能体协作分析结果并确定改进工具的方向。

**生成评估任务**

优秀评估任务包括：
- "安排下周与 Jane 开会讨论最新 Acme Corp 项目。附加上次项目规划会议的笔记并预订会议室。"
- "客户 ID 9182 反映因一次购买尝试被收费三次。找出所有相关日志条目并确定是否有其他客户受到同一问题影响。"

较弱的任务则简单直接，缺乏真实复杂性。

每个评估提示应配对一个可验证的响应或结果。验证器可以简单如字符串比对，或高级如由 Claude 判断响应。避免因格式、标点或有效替代措辞而拒绝正确响应的过度严格验证器。

**运行评估**

推荐使用直接 LLM API 调用以程序化方式运行评估。使用简单的智能体循环（while 循环包装交替的 LLM API 和工具调用）。

在评估智能体的系统提示中，建议指示智能体输出结构化响应块、推理和反馈块。在工具调用和响应块之前输出这些内容可通过触发链式思维（CoT）行为来增强 LLM 的有效智能。

如果使用 Claude 运行评估，可开启交错思维以获得类似的开箱即用功能。

除了顶级准确度外，还应收集其他指标，如单个工具调用和任务的总运行时间、工具调用总数、总令牌消耗和工具错误。

**分析结果**

智能体是发现问题的好帮手，可提供关于工具描述矛盾、低效实现和混淆架构的反馈。然而需注意，智能体在反馈和响应中"遗漏"的内容往往比所包含内容更重要。

观察智能体陷入困顿或混淆的地方。通过阅读评估智能体的推理和反馈来识别粗糙之处。审查原始记录（包括工具调用和响应）以捕捉智能体 CoT 中未明确描述的行为。

分析工具调用指标。大量冗余工具调用可能表明需要调整分页或令牌限制参数；大量因无效参数导致的工具错误可能表明工具需要更清晰的描述或更好的示例。

### 与智能体协作

你甚至可以让智能体分析结果并为你改进工具。只需连接评估智能体的记录并粘贴到 Claude Code 中。Claude 擅长分析记录并一次性重构多个工具——例如，确保在进行新更改时工具实现和描述保持自我一致。

本文大部分建议都来自于使用 Claude Code 反复优化我们的内部工具实现。我们的评估是在内部工作区基础上创建的，反映了内部工作流的复杂性，包括真实项目、文档和消息。

我们依靠留出的测试集以确保不会过度拟合"训练"评估。这些测试集表明，即使超越了手动编写或由 Claude 本身生成的"专家"工具实现，我们仍能获得额外的性能改进。

## 编写高效工具的原则

### 为智能体选择合适的工具

更多工具并不总是导致更好的结果。常见错误是工具仅仅包装现有软件功能或 API 端点，而不考虑工具是否适合智能体。这是因为智能体相比传统软件有不同的"affordances"——即它们对可采取行动的感知不同。

LLM 智能体的"上下文"有限（能处理的信息量有限），而计算机内存廉价充足。考虑在通讯录中搜索联系人的任务。传统软件可高效地逐个存储和处理联系人列表。

但若 LLM 智能体使用返回所有联系人的工具，则需逐个令牌读取，浪费有限的上下文空间。更好的方法（对智能体和人类都一样）是先跳到相关页面（可能按字母查找）。

建议构建少数针对特定高影响工作流的周密工具，与评估任务相匹配，然后逐步扩展。在通讯录案例中，可实现 `search_contacts` 或 `message_contact` 工具，而非 `list_contacts` 工具。

工具可整合功能，在后台处理多个离散操作或 API 调用。例如：

- 不实现 `list_users`、`list_events` 和 `create_event` 工具，而实现 `schedule_event` 工具来查找可用性并安排事件
- 不实现 `read_logs` 工具，而实现 `search_logs` 工具，只返回相关日志行和周围上下文
- 不实现 `get_customer_by_id`、`list_transactions` 和 `list_notes` 工具，而实现 `get_customer_context` 工具来汇编所有客户的最近相关信息

每个工具都应有清晰的独特目的。工具应使智能体能按人类处理任务的方式细分和解决任务，同时减少中间输出消耗的上下文。

过多或重叠的工具也会使智能体偏离高效策略。谨慎、有选择性地规划要构建的工具（或不构建）能带来真实收益。

### 为工具设置命名空间

AI 智能体可能获得来自数十个 MCP 服务器和数百个工具的访问权限——包括其他开发者的工具。当工具功能重叠或目的模糊时，智能体会对使用哪个工具感到困惑。

命名空间（将相关工具分组在共同前缀下）可帮助划分许多工具之间的边界。例如，按服务命名工具（如 `asana_search`、`jira_search`）和按资源命名（如 `asana_projects_search`、`asana_users_search`），可帮助智能体在适当时选择合适工具。

在选择前缀还是后缀命名方案方面有重要影响。效果因 LLM 而异，建议根据自己的评估选择命名方案。

通过选择性地实现工具名称反映任务的自然细分，可同时减少加载到智能体上下文中的工具和工具描述数量，并将智能体计算从智能体上下文卸载回工具调用本身。这降低了智能体犯错的总体风险。

### 从工具返回有意义的上下文

工具实现应仅向智能体返回高信号信息。应优先考虑上下文相关性而非灵活性，避免低级技术标识符（如 `uuid`、`256px_image_url`、`mime_type`）。字段如 `name`、`image_url` 和 `file_type` 更可能直接影响智能体的下游操作和响应。

智能体在处理自然语言名称、术语或标识符时的成功率明显高于处理密文标识符。仅仅将任意字母数字 UUID 解析为语义上更有意义和可解释的语言（甚至是 0 索引 ID 方案）能显著提高 Claude 在检索任务中的精确度，减少幻觉。

在某些情况下，智能体可能需要灵活与自然语言和技术标识符输出交互，以触发下游工具调用（例如 `search_user(name='jane')` → `send_message(id=12345)`）。可通过在工具中公开简单的 `response_format` 枚举参数来实现，允许智能体控制工具是否返回"concise"或"detailed"响应。

```
enum ResponseFormat {
   DETAILED = "detailed",
   CONCISE = "concise"
}
```

可添加更多格式获得更大灵活性，类似 GraphQL 可选择接收的确切信息。

详细工具响应包含所有信息（206 令牌），简洁响应仅包含线程内容和必要标识符以触发后续调用（72 令牌），在本例中使用约⅓的令牌。

甚至工具响应结构——如 XML、JSON 或 Markdown——也能影响评估性能：没有通用方案。这是因为 LLM 经过下一个令牌预测训练，往往在与其训练数据相匹配的格式上表现更好。最优响应结构因任务和智能体而异。建议基于自己的评估选择最佳响应结构。

### 优化工具响应的令牌效率

优化上下文质量很重要，优化返回给智能体的上下文"数量"同样重要。

建议为任何可能消耗大量上下文的工具响应实现分页、范围选择、过滤和/或截断的某种组合，配合明智的默认参数值。对于 Claude Code，我们默认将工具响应限制在 25,000 令牌。预期智能体的有效上下文长度会随时间增长，但对上下文高效工具的需求将持续。

如选择截断响应，务必用有用指令引导智能体。可直接鼓励智能体采用更令牌高效的策略，如进行多次小的有针对性的搜索而非单一宽泛搜索。同样，若工具调用抛出错误（例如输入验证期间），可对工程错误响应以清晰传达具体且可行的改进，而非不透明的错误代码或追踪。

截断工具响应示例展示了实现边界检查和有用指导的最佳实践。

不有用的错误响应仅返回异常堆栈追踪，而有用的错误响应则清晰说明问题并提供示例。

### 为工具描述进行提示工程

现在来到改进工具的最有效方法之一：对工具描述和规范进行提示工程。由于这些被加载到智能体的上下文中，它们可集体引导智能体走向高效的工具调用行为。

编写工具描述和规范时，想象你如何向团队新成员描述工具。考虑你可能隐含携带的上下文——专门的查询格式、小众术语定义、底层资源之间的关系——并将其明确化。通过明确描述（并用严格数据模型强制执行）预期输入和输出来避免歧义。特别是，输入参数应明确命名：不用 `user`，而用 `user_id`。

通过评估，你可更有信心地衡量提示工程的影响。即使工具描述的微小细化也能产生显著改进。Claude Sonnet 3.5 在 SWE-bench Verified 评估上实现了最先进的性能，我们进行了精确的工具描述细化，大幅降低错误率并改进任务完成。

开发者指南中有工具定义的其他最佳实践。如为 Claude 构建工具，还建议阅读工具如何动态加载到 Claude 系统提示中。最后，若为 MCP 服务器编写工具，工具注解可帮助披露哪些工具需要开放式访问或进行破坏性变更。

## 展望

为智能体构建高效工具需要将软件开发实践从可预测、确定性的模式重新定向到非确定性的模式。

通过本文所述的迭代、评估驱动的过程，我们发现了使工具成功的一致模式：高效工具有意明确定义、谨慎使用智能体上下文、能以多种工作流组合、使智能体能直观解决真实任务。

未来，智能体与世界交互的具体机制预期将演变——从 MCP 协议更新到底层 LLM 升级。采用系统化、评估驱动的方法改进智能体工具，能确保随着智能体愈发能干，它们使用的工具也随之进化。

---

**致谢**

由 Ken Aizawa 撰写，获得来自研究（Barry Zhang、Zachary Witten、Daniel Jiang、Sami Al-Sheikh、Matt Bell、Maggie Vo）、MCP（Theodora Chu、John Welsh、David Soria Parra、Adam Jones）、产品工程（Santiago Seira）、市场营销（Molly Vorwerck）、设计（Drew Roper）和应用 AI（Christian Ryan、Alexander Bricken）同事的宝贵贡献。
